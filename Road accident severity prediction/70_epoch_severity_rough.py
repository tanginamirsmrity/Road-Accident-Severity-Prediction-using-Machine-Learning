# -*- coding: utf-8 -*-
"""70 epoch Severity rough.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TQoAXB32ONWuVJ2AVUwbT4sRiZYM_j2i
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import confusion_matrix
from sklearn.preprocessing import OneHotEncoder

# load the boston dataset
# Replace 'input.xlsx' with the path to your Excel file
file_path = '/RTA Dataset.csv'

# Read the Excel file
dataframe = pd.read_csv(file_path)

dataframe

dataframe.head()

import pandas as pd

null_counts = dataframe.isnull().sum()

print("Before Null value counts:")
print(null_counts)

for column in dataframe.columns:
    # Replace null values with 'N/A'
    dataframe[column].fillna('N/A', inplace=True)
    import pandas as pd


null_counts = dataframe.isnull().sum()

print("After Null value counts:")
print(null_counts)

for column in dataframe.columns:
    unique_values = dataframe[column].unique()
    print(f"Unique values in column '{column}': {unique_values}")

for column in dataframe.columns:
    dataframe[column] = dataframe[column].astype(str)

# Apply LabelEncoder to categorical columns
label_encoder = LabelEncoder()
for column in dataframe.columns:
    if dataframe[column].dtype == 'object':
        dataframe[column] = label_encoder.fit_transform(dataframe[column])

# Define feature matrix (X) and response vector (y)
X = dataframe.iloc[:, :-1]
y = dataframe.iloc[:, -1:]
y

import pandas as pd
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Dense
# Z-score normalization
scaler = StandardScaler()
X = scaler.fit_transform(X)

# Encode class values as integers
encoder = LabelEncoder()
encoder.fit(y)
y = encoder.transform(y)

# Splitting X and y into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

# Convert integers to dummy variables (i.e., one-hot encoded)
y_train = to_categorical(y_train)
y_train

from tensorflow.keras.layers import Dense, LSTM, Dropout

model = Sequential()
model.add(Dense(512, input_dim=31, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(256, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(32, activation='relu'))
model.add(Dense(16, activation='relu'))
model.add(Dense(8, activation='relu'))
model.add(Dropout(0.15))
model.add(Dense(3, activation='softmax'))

# compile the keras model
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# fit the keras model on the dataset
model.fit(X_train, y_train, epochs=70, batch_size=32)

acc = model.evaluate(X_train, y_train)
print("Loss:", acc[0], " Accuracy:", acc[1])